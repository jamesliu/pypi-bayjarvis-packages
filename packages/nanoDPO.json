{
  "info": {
    "author": "James Liu",
    "author_email": "",
    "bugtrack_url": null,
    "classifiers": [
      "License :: OSI Approved :: Apache Software License",
      "Programming Language :: Python :: 2",
      "Programming Language :: Python :: 2.7",
      "Programming Language :: Python :: 3",
      "Programming Language :: Python :: 3.10",
      "Programming Language :: Python :: 3.11",
      "Programming Language :: Python :: 3.4",
      "Programming Language :: Python :: 3.5",
      "Programming Language :: Python :: 3.6",
      "Programming Language :: Python :: 3.7",
      "Programming Language :: Python :: 3.8",
      "Programming Language :: Python :: 3.9"
    ],
    "description": "\n# nanoDPO: Direct Preference Optimization for Time Series Data\n\n[![PyPI](https://img.shields.io/pypi/v/nanoDPO.svg)](https://pypi.org/project/nanoDPO/)\n[![Changelog](https://img.shields.io/github/v/release/jamesliu/nanoDPO?include_prereleases&label=changelog)](https://github.com/jamesliu/nanoDPO/releases)\n[![Tests](https://github.com/jamesliu/nanoDPO/workflows/Test/badge.svg)](https://github.com/jamesliu/nanoDPO/actions?query=workflow%3ATest)\n[![Documentation Status](https://readthedocs.org/projects/nanoDPO/badge/?version=stable)](http://nanoDPO.readthedocs.org/en/stable/?badge=stable)\n[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/jamesliu/nanoDPO/blob/main/LICENSE)\n\n## Introduction\nWelcome to `nanoDPO` â€“ a novel, cutting-edge library for Direct Preference Optimization (DPO) tailored for time series data. Inspired by the concept of utilizing DPO in fine-tuning unsupervised Language Models (LMs) to align with user preferences, `nanoDPO` pivots this approach to the realm of time series analysis. This library offers a unique perspective and toolset for time series forecasting, leveraging the principles of DPO to model and predict preferences in sequential data.\n\n## Installation\nTo get started with `nanoDPO`, simply install the package using pip:\n\n```bash\npip install nanoDPO\n```\n\n## Key Features\n\n* Causal Transformer & Simple Sequence Model: Incorporates both a Causal Transformer and a LSTM-based Simple Sequence Model for diverse modeling needs.\n* Preference Data Simulation: Utilizes a custom function, simulate_dpo_dataset_noise, to generate synthetic preference-based time series data.\n* Sequence Data Preparation: Prepares data for training with prepare_sequence_datasets, aligning time series data with the DPO framework.\n* DPO Training with PyTorch: Leverages the power of PyTorch for efficient and effective model training, complete with customizable parameters.\n* MulticlassTrainer provides an additional approach to handle time series data, focusing on traditional multiclass classification tasks. \n* Cross-Entropy Loss for Multiclass Classification: Optimized for handling multiple classes in time series data.\n* Customizable Training and Evaluation: Flexible parameters for epochs, batch size, and learning rate.\n* Model Evaluation and Visualization: Offers tools for model evaluation and metrics visualization, ensuring an insightful analysis of performance.\n\n## Usage\n\nImport the necessary modules from nanoDPO, including the CausalTransformer, SimpleSequenceModel, and dataset preparation functions. Utilize the DPOOneModelTrainer for Direct Preference Optimization or MulticlassTrainer for conventional multiclass training.\n\n```python\nimport torch\nfrom nanodpo.causal_transformer import CausalTransformer\nfrom nanodpo.simple_sequence_model import SimpleSequenceModel\nfrom nanodpo.preference_data import simulate_dpo_dataset_noise\nfrom nanodpo.sequence_data import prepare_sequence_datasets\nfrom nanodpo.dpo_onemodel_trainer import DPOOneModelTrainer\nfrom nanodpo.multiclass_trainer import MulticlassTrainer\n\n# Initialize and train your model\n...\nmodel = CausalTransformer(d_feature= feature_dim, d_model=d_model, n_head=n_head, n_layer=n_layer, \n                          num_actions=num_actions, max_len=sequence_len,\n                          device=device).to(device)\n...\ntrainer = DPOOneModelTrainer(model=model, model_dir=f\"dpo_{model_type}_model/\", device=device,\n                             learning_rate=learning_rate, batch_size=batch_size)\ntrainer.train(train_dataset, test_dataset, epochs=epochs, eval_interval=eval_interval)\n# Evaluate and visualize the results\ntrainer.plot_metrics()\ntrainer.evaluate(test_dataset)\n```\n\n![wandb dpo causal_transformer](https://github.com/jamesliu/nanoDPO/blob/main/assets/dpo_causal_transformer_wandb.png)\n\n## License\n\nnanoDPO is licensed under the Apache License 2.0. See the [LICENSE](https://github.com/jamesliu/nanoDPO/blob/main/LICENSE) file for more details.\n\n## Acknowledgments\n\nInspired by the paper \"[Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2305.18290),\" nanoDPO extends the concept of DPO to the domain of time series data, opening new avenues for research and application.\n\n## Citation\n\n```bibtex\n@misc{rafailov2023direct,\n  title   = {Direct Preference Optimization: Your Language Model is Secretly a Reward Model}, \n  author  = {Rafael Rafailov and Archit Sharma and Eric Mitchell and Stefano Ermon and Christopher D. Manning and Chelsea Finn},\n  year    = {2023},\n  eprint  = {2305.18290},\n  archivePrefix = {arXiv},\n  primaryClass = {cs.LG}\n}\n```\n",
    "description_content_type": "text/markdown",
    "docs_url": null,
    "download_url": "",
    "downloads": {
      "last_day": -1,
      "last_month": -1,
      "last_week": -1
    },
    "home_page": "",
    "keywords": "",
    "license": "Apache-2.0",
    "maintainer": "",
    "maintainer_email": "",
    "name": "nanoDPO",
    "package_url": "https://pypi.org/project/nanoDPO/",
    "platform": null,
    "project_url": "https://pypi.org/project/nanoDPO/",
    "project_urls": null,
    "release_url": "https://pypi.org/project/nanoDPO/0.1.post1/",
    "requires_dist": null,
    "requires_python": "",
    "summary": "A nimble and innovative implementation of the Direct Preference Optimization (DPO) algorithm with Causal Transformer and LSTM model for time series data, inspired by the paper of DPO in fine-tuning unsupervised Language Models",
    "version": "0.1.post1",
    "yanked": false,
    "yanked_reason": null
  },
  "last_serial": 20784601,
  "releases": {
    "0.1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "5aa559fb1143a9bb2fc0cfd1dc797411396315e2d736bc582ae61c9f0477f4f6",
          "md5": "65df6490dbf36f6ff5069a22cc187e1a",
          "sha256": "c947b14eb0cd8ed20b533c191f303dd853c71d7f31102669201a59439211a125"
        },
        "downloads": -1,
        "filename": "nanodpo-0.1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "65df6490dbf36f6ff5069a22cc187e1a",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 11808,
        "upload_time": "2023-11-21T06:01:27",
        "upload_time_iso_8601": "2023-11-21T06:01:27.528471Z",
        "url": "https://files.pythonhosted.org/packages/5a/a5/59fb1143a9bb2fc0cfd1dc797411396315e2d736bc582ae61c9f0477f4f6/nanodpo-0.1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "1c617cfab0dbadb637e2f4e7a5faab9c3a1ff764704bfa9197b42f03012360d3",
          "md5": "94aea3ae0d8af25baca70a516a69ee92",
          "sha256": "509df94cb837d630ffd2cdd52dd219b940fb0aa3eac001a9a6362285163d936f"
        },
        "downloads": -1,
        "filename": "nanodpo-0.1.tar.gz",
        "has_sig": false,
        "md5_digest": "94aea3ae0d8af25baca70a516a69ee92",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 8461,
        "upload_time": "2023-11-21T06:01:29",
        "upload_time_iso_8601": "2023-11-21T06:01:29.051364Z",
        "url": "https://files.pythonhosted.org/packages/1c/61/7cfab0dbadb637e2f4e7a5faab9c3a1ff764704bfa9197b42f03012360d3/nanodpo-0.1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ],
    "0.1.post1": [
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "7b6996ca903dfabc9e549b3545f14b5f4a4ecd302cef7354c60e1c57ff582d33",
          "md5": "8a4336931541ae20f170d4a7107cc087",
          "sha256": "ac1593cf854a834f43274b41744b426d20b00f9ae5c1a29f15c4f5dfdb4e9a0a"
        },
        "downloads": -1,
        "filename": "nanodpo-0.1.post1-py2.py3-none-any.whl",
        "has_sig": false,
        "md5_digest": "8a4336931541ae20f170d4a7107cc087",
        "packagetype": "bdist_wheel",
        "python_version": "py2.py3",
        "requires_python": null,
        "size": 17545,
        "upload_time": "2023-11-25T01:03:58",
        "upload_time_iso_8601": "2023-11-25T01:03:58.374206Z",
        "url": "https://files.pythonhosted.org/packages/7b/69/96ca903dfabc9e549b3545f14b5f4a4ecd302cef7354c60e1c57ff582d33/nanodpo-0.1.post1-py2.py3-none-any.whl",
        "yanked": false,
        "yanked_reason": null
      },
      {
        "comment_text": "",
        "digests": {
          "blake2b_256": "e8c966edd600487776f1abf806338acae98a065d5aba9893871dd6fc3b87bc72",
          "md5": "969ff8a253df548697bac35c1f1088ea",
          "sha256": "8577ba21441395d5fd1259b1109f4636e3c61d862620b31d653733a737b53081"
        },
        "downloads": -1,
        "filename": "nanodpo-0.1.post1.tar.gz",
        "has_sig": false,
        "md5_digest": "969ff8a253df548697bac35c1f1088ea",
        "packagetype": "sdist",
        "python_version": "source",
        "requires_python": null,
        "size": 14253,
        "upload_time": "2023-11-25T01:04:00",
        "upload_time_iso_8601": "2023-11-25T01:04:00.093433Z",
        "url": "https://files.pythonhosted.org/packages/e8/c9/66edd600487776f1abf806338acae98a065d5aba9893871dd6fc3b87bc72/nanodpo-0.1.post1.tar.gz",
        "yanked": false,
        "yanked_reason": null
      }
    ]
  },
  "urls": [
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "7b6996ca903dfabc9e549b3545f14b5f4a4ecd302cef7354c60e1c57ff582d33",
        "md5": "8a4336931541ae20f170d4a7107cc087",
        "sha256": "ac1593cf854a834f43274b41744b426d20b00f9ae5c1a29f15c4f5dfdb4e9a0a"
      },
      "downloads": -1,
      "filename": "nanodpo-0.1.post1-py2.py3-none-any.whl",
      "has_sig": false,
      "md5_digest": "8a4336931541ae20f170d4a7107cc087",
      "packagetype": "bdist_wheel",
      "python_version": "py2.py3",
      "requires_python": null,
      "size": 17545,
      "upload_time": "2023-11-25T01:03:58",
      "upload_time_iso_8601": "2023-11-25T01:03:58.374206Z",
      "url": "https://files.pythonhosted.org/packages/7b/69/96ca903dfabc9e549b3545f14b5f4a4ecd302cef7354c60e1c57ff582d33/nanodpo-0.1.post1-py2.py3-none-any.whl",
      "yanked": false,
      "yanked_reason": null
    },
    {
      "comment_text": "",
      "digests": {
        "blake2b_256": "e8c966edd600487776f1abf806338acae98a065d5aba9893871dd6fc3b87bc72",
        "md5": "969ff8a253df548697bac35c1f1088ea",
        "sha256": "8577ba21441395d5fd1259b1109f4636e3c61d862620b31d653733a737b53081"
      },
      "downloads": -1,
      "filename": "nanodpo-0.1.post1.tar.gz",
      "has_sig": false,
      "md5_digest": "969ff8a253df548697bac35c1f1088ea",
      "packagetype": "sdist",
      "python_version": "source",
      "requires_python": null,
      "size": 14253,
      "upload_time": "2023-11-25T01:04:00",
      "upload_time_iso_8601": "2023-11-25T01:04:00.093433Z",
      "url": "https://files.pythonhosted.org/packages/e8/c9/66edd600487776f1abf806338acae98a065d5aba9893871dd6fc3b87bc72/nanodpo-0.1.post1.tar.gz",
      "yanked": false,
      "yanked_reason": null
    }
  ],
  "vulnerabilities": []
}
